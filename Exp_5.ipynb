{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNx2f/PFajOn/6XygAxGnxj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnshulSingh-eZ/Machine_Learning_Lab_23CS067/blob/main/Exp_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tofzRV_DfBfH",
        "outputId": "b364061e-53d2-4d32-aa6c-9e15602b6f1a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.10.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Bj5CBU3ZebWX"
      },
      "outputs": [],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "adult = fetch_ucirepo(id=2)\n",
        "X = adult.data.features # features (pandas DataFrame)\n",
        "Y = adult.data.targets # target (pandas DataFrame)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.dtypes)\n",
        "print(\"_________________Y__________________\")\n",
        "print(Y.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ5EzBm2wthP",
        "outputId": "db1fd00a-b75d-4bd0-faf0-b1117ab74ee9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age                int64\n",
            "workclass         object\n",
            "fnlwgt             int64\n",
            "education         object\n",
            "education-num      int64\n",
            "marital-status    object\n",
            "occupation        object\n",
            "relationship      object\n",
            "race              object\n",
            "sex               object\n",
            "capital-gain       int64\n",
            "capital-loss       int64\n",
            "hours-per-week     int64\n",
            "native-country    object\n",
            "dtype: object\n",
            "_________________Y__________________\n",
            "income    object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "enc = LabelEncoder()"
      ],
      "metadata": {
        "id": "1zZvh_F2wta2"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in X.columns:\n",
        "  if X[col].dtype == 'object':\n",
        "    X[col] = enc.fit_transform(X[col])\n",
        "\n",
        "Y = enc.fit_transform(Y.values.ravel())\n",
        "Y = Y.reshape(-1, 1)\n",
        "\n",
        "X = X.astype(float)\n",
        "Y = Y.astype(float)"
      ],
      "metadata": {
        "id": "QlhnEZN0wtYM"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TECsn1y2wtTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "UAiOYvvYfGsT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Splitting data into train, test and validation dataset (60, 20, 20)**"
      ],
      "metadata": {
        "id": "K6yNT_5r_WAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
        "    X, Y,\n",
        "    train_size = 0.6\n",
        ")\n",
        "X_test, X_val, Y_test, Y_val = train_test_split(\n",
        "    X_temp, Y_temp,\n",
        "    train_size = 0.5\n",
        ")"
      ],
      "metadata": {
        "id": "T55sPkqKghcf"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8RXn9R-ghZG",
        "outputId": "5ba25fce-cb58-42d4-9cb2-6490e4127e85"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29305, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node(object):\n",
        "  def __init__(self, feature=None, threshold=None, left=None, right=None, gain=None, value=None):\n",
        "    self.feature = feature\n",
        "    self.threshold = threshold\n",
        "    self.left = left\n",
        "    self.right = right\n",
        "    self.gain = gain\n",
        "    self.value = value"
      ],
      "metadata": {
        "id": "t_ch6CybReS-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Decision Tree Class**"
      ],
      "metadata": {
        "id": "Dqfxk6MP_ft7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class decisionTree(object):\n",
        "  def __init__(self, max_depth = 2, min_samples = 2):\n",
        "    self.max_depth = max_depth\n",
        "    self.min_samples = min_samples\n",
        "\n",
        "  def split_dataset(self, dataset, feature, threshold):\n",
        "    left_partition = []\n",
        "    right_partition = []\n",
        "    for r in dataset:\n",
        "      if(r[feature] <= threshold):\n",
        "        left_partition.append(r)\n",
        "      else:\n",
        "        right_partition.append(r)\n",
        "\n",
        "    left_partition = np.array(left_partition)\n",
        "    right_partition = np.array(right_partition)\n",
        "    return left_partition, right_partition\n",
        "\n",
        "  def entropy(self, y):\n",
        "    entropy = 0\n",
        "    labels = np.unique(y)\n",
        "    for label in labels:\n",
        "      total_labels = y[y==label]\n",
        "      x = len(total_labels)/ len(y)\n",
        "      entropy += -x*np.log2(x)\n",
        "    return entropy\n",
        "\n",
        "  def gini(self, y):\n",
        "    labels = np.unique(y)\n",
        "    gini = 1.0\n",
        "    for label in labels:\n",
        "        p = np.sum(y == label) / len(y)\n",
        "        gini -= p**2\n",
        "    return gini\n",
        "\n",
        "\n",
        "  def info_gain(self, parent, right, left):\n",
        "    parent_entropy = self.entropy(parent)\n",
        "    right_entropy = self.entropy(right)\n",
        "    left_entropy = self.entropy(left)\n",
        "    right_wt = len(right)/len(parent)\n",
        "    left_wt = len(left)/len(parent)\n",
        "    weighted_entropy  = right_wt*right_entropy + left_wt*left_entropy\n",
        "    infogain = parent_entropy - weighted_entropy\n",
        "    return infogain\n",
        "\n",
        "  def best_split(self, dataset, num_samples, num_features):\n",
        "    best_split = {\"gain\":- 1, \"feature\": None, \"threshold\": None}\n",
        "    for i in range(num_features):\n",
        "      features_values = dataset[:, i]\n",
        "      uniq_features_values = np.unique(features_values)\n",
        "      for threshold in uniq_features_values:\n",
        "        left_dataset, right_dataset = self.split_dataset(dataset, i, threshold)\n",
        "        if len(left_dataset) > 0 and len(right_dataset) > 0:\n",
        "          y, left_child, right_child = dataset[:,-1], left_dataset[:,-1], right_dataset[:,-1]\n",
        "          information = self.info_gain(y, left_child, right_child)\n",
        "          if(information>best_split[\"gain\"]):\n",
        "            best_split[\"gain\"] = information\n",
        "            best_split[\"feature\"] = i\n",
        "            best_split[\"threshold\"] = threshold\n",
        "            best_split[\"left_dataset\"] = left_dataset\n",
        "            best_split[\"right_dataset\"] = right_dataset\n",
        "    return best_split\n",
        "\n",
        "  def calc_leaf_val(self, y):\n",
        "    y = list(y)\n",
        "    mode = max(y, key=y.count)\n",
        "    return mode\n",
        "\n",
        "  def build_tree(self, dataset, current_depth = 0):\n",
        "    x, y  = dataset[:,:-1], dataset[:,-1]\n",
        "    n_samples, n_features = x.shape\n",
        "    if n_samples >= self.min_samples and current_depth <= self.max_depth:\n",
        "      best_split = self.best_split(dataset, n_samples, n_features)\n",
        "      if(best_split[\"gain\"]):\n",
        "        left_node = self.build_tree(best_split[\"left_dataset\"], current_depth+1)\n",
        "        right_node = self.build_tree(best_split[\"right_dataset\"], current_depth+1)\n",
        "        return Node(best_split[\"feature\"], best_split[\"threshold\"], left_node, right_node, best_split[\"gain\"])\n",
        "    leaf_val = self.calc_leaf_val(y)\n",
        "    return Node(value=leaf_val)\n",
        "\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    dataset = np.concatenate((X, Y), axis=1)\n",
        "    self.root = self.build_tree(dataset)\n",
        "\n",
        "  def make_prediction(self, X, node):\n",
        "    if node.value is not None:\n",
        "      return node.value\n",
        "    else:\n",
        "      feature = X[node.feature]\n",
        "      if feature<=node.threshold:\n",
        "        return self.make_prediction(X, node.left)\n",
        "      return self.make_prediction(X, node.right)\n",
        "\n",
        "  def predict(self, X):\n",
        "    predictions = []\n",
        "    for x in X:\n",
        "      prediction = self.make_prediction(x, self.root)\n",
        "      predictions.append(prediction)\n",
        "    np.array(predictions)\n",
        "    return predictions\n",
        "\n",
        "  def post_prune(self, node, X_val, Y_val):\n",
        "    if node.left is not None and node.right is not None:\n",
        "        self.post_prune(node.left, X_val, Y_val)\n",
        "        self.post_prune(node.right, X_val, Y_val)\n",
        "\n",
        "        backup_left = node.left\n",
        "        backup_right = node.right\n",
        "        backup_feature = node.feature\n",
        "        backup_threshold = node.threshold\n",
        "        backup_value = node.value\n",
        "\n",
        "        node.left = None\n",
        "        node.right = None\n",
        "        node.feature = None\n",
        "        node.threshold = None\n",
        "        node.value = self.calc_leaf_val(self.get_node_labels(node, X_val, Y_val))\n",
        "\n",
        "        y_pred = np.array([self.make_prediction(x, self.root) for x in X_val])\n",
        "        acc_new = (y_pred == Y_val).mean()\n",
        "        y_pred_orig = np.array([self.make_prediction(x, self.root) for x in X_val])\n",
        "        acc_orig = (y_pred_orig == Y_val).mean()\n",
        "        if acc_new < acc_orig:\n",
        "            node.left = backup_left\n",
        "            node.right = backup_right\n",
        "            node.feature = backup_feature\n",
        "            node.threshold = backup_threshold\n",
        "            node.value = backup_value\n"
      ],
      "metadata": {
        "id": "Yib38lThghUE"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    y_true = y_true.flatten()\n",
        "    total_samples = len(y_true)\n",
        "    correct_predictions = np.sum(y_true == y_pred)\n",
        "    return (correct_predictions / total_samples)\n",
        "\n"
      ],
      "metadata": {
        "id": "91j9T_9Cun1P"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NBrCLsuLunym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sHIMgVnT6EEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## No tuning (with validation set) - Basic Pre Pruning - 56% accuracy"
      ],
      "metadata": {
        "id": "K-TlOIN77L12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = decisionTree()\n",
        "model.fit(X_train, Y_train)\n",
        "predictions = model.predict(X_test)\n",
        "acc = accuracy(Y_test, predictions)\n",
        "print(acc)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI1M2KfrSFZT",
        "outputId": "d9998797-669b-4e95-fb1f-afbb24458522"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5611179361179361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4oGCB_ab86Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Since Training took a lot of time, we will be training it again on a smaller dataset!!**\n",
        "\n",
        "Tuning Hyperparameters using validation data"
      ],
      "metadata": {
        "id": "vn6oM08e9xii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[:500]\n",
        "Y = Y[:500]"
      ],
      "metadata": {
        "id": "ZgjXayj486BM"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0\n",
        "best_params = {}\n",
        "\n",
        "for depth in [2, 4, 6, 8]:\n",
        "    for min_s in [2, 5, 10]:\n",
        "        model = decisionTree(max_depth=depth, min_samples=min_s)\n",
        "        model.fit(X_train, Y_train)\n",
        "        y_val_pred = model.predict(X_val)\n",
        "        acc = (y_val_pred == Y_val).mean()\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_params = {'max_depth': depth, 'min_samples': min_s}\n",
        "\n",
        "print(\"Best validation accuracy:\", best_acc)\n",
        "print(\"Best params:\", best_params)\n"
      ],
      "metadata": {
        "id": "Quy6BPLA85--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uAufgCOj858c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PWgf-bza855z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}